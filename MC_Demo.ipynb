{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chains\n",
    "## Introduction\n",
    "https://en.wikipedia.org/wiki/Markov_chain  \n",
    "From Wikipedia: A Markov chain is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event.  \n",
    "\n",
    "Mathematically a Markov chain can be described as follows:  \n",
    "Given a set of discrete states $s_i \\in S$ and events defined as discrete times with an assigned state $X_t=(t,s_i)$, $t \\in \\mathbb{Z}$  \n",
    "A Markov chain defines a model for a sequence of events as a probability distribution based on a previous event's state:  \n",
    "$$ \\Pr \\left (X_{n+1}=(n+1,s_i) \\mid X_{n}=(n,s_j) \\right ) = p_{i,j} $$  \n",
    "Such that\n",
    "$$ \\sum_{j} p_{i,j} = 1 $$  \n",
    "Note that $p_{i,j}$ defines a stochastic state transition matrix  \n",
    "https://en.wikipedia.org/wiki/Stochastic_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# Data reading and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# The text Markov parser and generator\n",
    "import markovify\n",
    "\n",
    "# Graph library\n",
    "import networkx as nx\n",
    "from networkx.drawing.nx_agraph import to_agraph\n",
    "\n",
    "# Drawing and rendering\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "# Image display\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple Markov chain\n",
    "edge_list = [\n",
    "    ('A', 'B', {'weight':0.2}),\n",
    "    ('A', 'C', {'weight':0.4}),\n",
    "    ('A', 'D', {'weight':0.4}),\n",
    "    ('B', 'A', {'weight':0.5}),\n",
    "    ('B', 'C', {'weight':0.5}),\n",
    "    ('C', 'B', {'weight':0.5}),\n",
    "    ('C', 'C', {'weight':0.5}),\n",
    "    ('D', 'C', {'weight':1.0})\n",
    "]\n",
    "G_example = nx.MultiDiGraph(edge_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_example_PGV = to_agraph(G_example)\n",
    "G_example_PGV.node_attr['shape'] = 'circle'\n",
    "G_example_PGV.graph_attr['splines'] = 'true'\n",
    "G_example_PGV.graph_attr['esep'] = '2'\n",
    "for e1,e2,edge_data in G_example.edges(data=True):\n",
    "    G_example_PGV.get_edge(e1, e2).attr['label'] = edge_data['weight']\n",
    "    \n",
    "G_example_PGV.layout('circo')\n",
    "Image(G_example_PGV.draw(format='png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(G_example.nodes()))\n",
    "nx.to_numpy_matrix(G_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocomplete and Text Generation\n",
    "Using Markov chains we can essencially create a probablity distribution over possible sentences created by chaining words that come after one-another, and then sample from this distribution to generate text!  \n",
    "### Text Generation Basic Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model = markovify.Text(\"I am One. I am Two. I am Three.\", state_size=1)\n",
    "text_model.chain.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model.make_sentence(test_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn into a dict with probabilities instead of counts\n",
    "G_dict = [(''.join(word),child_word,{'weight':float(weight)/sum(children_words.values())}) for word,children_words in text_model.chain.model.items() for child_word,weight in children_words.items()]\n",
    "# Turn into a NetworkX object\n",
    "G = nx.MultiDiGraph(G_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(G.edges(data=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_example_PGV = to_agraph(G)\n",
    "G_example_PGV.node_attr['shape'] = 'circle'\n",
    "G_example_PGV.graph_attr['splines'] = 'true'\n",
    "G_example_PGV.graph_attr['esep'] = '2'\n",
    "for e1,e2,edge_data in G.edges(data=True):\n",
    "    G_example_PGV.get_edge(e1, e2).attr['label'] = round(edge_data['weight'], 3)\n",
    "\n",
    "G_example_PGV.layout('dot')\n",
    "Image(G_example_PGV.draw(format='png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(G.nodes()))\n",
    "nx.to_numpy_matrix(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Generation Lyrics Example\n",
    "**NOTE**: For this example you will need to obtain a dataset of lyics (newline separated, starting with the line 'lyrics'). Choose your favorite artist and grab a copy from your favorite lyrics source! A dataset has not been provided due to copyright concerns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('lyrics.csv').fillna('')\n",
    "lyrics_corpus = '\\n'.join(df['lyrics'].tolist())\n",
    "lyrics_corpus = lyrics_corpus.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_model = markovify.Text(lyrics_corpus, state_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(lyrics_model.make_sentence())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autocomplete Lyrics Example\n",
    "**NOTE**: See above  \n",
    "The Markovian model is the very idea behind autocomplete on your phone: based upon the last few words you wrote, what are you most likely to write next?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This time we're only going to look for the next word after 1\n",
    "lyrics_model = markovify.Text(lyrics_corpus, state_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List the top most frequently used following words\n",
    "sorted(list(lyrics_model.chain.model[('___BEGIN__',)].items()), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PageRank\n",
    "PageRank is the algorithm invented by Google founders Larry Page and Sergey Brin and is one of the primary metrics used by the Google search engine.  \n",
    "The PageRank algorithm models a user's path through pages on the internet by clicking links as a Markov chain. The algorithm seeks to find the likelihood of a user landing on a given page. It is essentially a form of **eigencentrality** of the Markov chain's graph.  \n",
    "https://en.wikipedia.org/wiki/PageRank  \n",
    "\n",
    "### Mathematical Preliminary\n",
    "Given a probability distribution over the states in a Markov chain at time $t$ as a row vector $\\vec{s}_t$ the probability distribution over the states at time $t+1$ is given in by the stochastic state transition matrix $\\bar{P}$:  \n",
    "$$\\vec{s}_{t+1} = \\vec{s}_{t} \\bar{P}$$\n",
    "\n",
    "### Definition of Eigencentrality\n",
    "A row eigenvector of the matrix $\\bar{P}$ is defined by the equation:  \n",
    "$$\\vec{v} \\bar{P} = \\lambda\\vec{v}$$  \n",
    "If $\\lambda = 1 $ then $\\vec{v}$ is fixed point of the matrix multiplication with $\\bar{P}$.  \n",
    "What does this mean for a Markov chain? A fixed point would be a probability distribution of ending up in any of the states after infinite transitions: the long term probability.\n",
    "\n",
    "### Definition of PageRank and the Google Matrix\n",
    "PageRank models a person surfing the web by clicking on links between pages. For simplicity, they are assumed to have an equal chance of clicking on any link on a page. Sounds like a Markov chain! They are also assumed to only have a probability $\\alpha$ of continuing to surf at any given step. Given a \"universe\" of web pages and the links between them, how do we find the probability of landing on a given page?  \n",
    "We can accomplish this by adding a \"quit transitioning\" term to our eigenvector formula:  \n",
    "$$\\vec{R} = \\alpha\\vec{R}\\bar{P} + \\frac{1-\\alpha}{N}\\vec{1}$$\n",
    "Where $\\vec{1}$ is a vector of all $1$s  \n",
    "\n",
    "So how do we compute the solution do this? Well since $\\vec{R}$ is a probability distribution, its components must sum to 1 (i.e. the $L^{1}$ norm is $1$), therefore we can rewrite the PageRank expression as:  \n",
    "$$\\vec{R} = \\vec{R} \\left ( \\alpha\\bar{P} + \\frac{1-\\alpha}{N}\\bar{1} \\right ) = \\vec{R} \\bar{G}$$\n",
    "Where $\\bar{1}$ is a matrix of all $1$s  \n",
    "$\\bar{G}$ is what's known as the Google matrix.  \n",
    "\n",
    "And so we're back to an eigenvector problem, which can be solved by usual eigenvector solving techniques. In the case of the PageRank problem, fixed point iteration converages quite rapidly.    \n",
    "https://en.wikipedia.org/wiki/Google_matrix  \n",
    "https://en.wikipedia.org/wiki/Fixed-point_iteration  \n",
    "### A Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're not going to write a spider to crawl the web for this demo\n",
    "edge_list = [\n",
    "    ('The Popular Kid', 'Follower1'),\n",
    "    ('The Popular Kid', 'Best Friend'),\n",
    "    ('The Popular Kid', 'Follower2'),\n",
    "    ('Follower1', 'The Popular Kid'),\n",
    "    ('Follower1', 'Best Friend'),\n",
    "    ('Best Friend', 'The Popular Kid'),\n",
    "    ('Follower2', 'The Popular Kid'),\n",
    "    ('Follower2','Best Friend')\n",
    "]\n",
    "PR_graph = nx.MultiDiGraph(edge_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_example_PGV = to_agraph(PR_graph)\n",
    "G_example_PGV.node_attr['shape'] = 'circle'\n",
    "G_example_PGV.graph_attr['splines'] = 'true'\n",
    "G_example_PGV.graph_attr['esep'] = '2'\n",
    "\n",
    "G_example_PGV.layout('circo')\n",
    "Image(G_example_PGV.draw(format='png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NetworkX library actually comes with functions to perform the PageRank algorithm and compute the Google matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(PR_graph.nodes()))\n",
    "print(nx.to_numpy_matrix(PR_graph))\n",
    "nx.google_matrix(PR_graph, alpha=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.pagerank_numpy(PR_graph, alpha=0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the PageRank algorithm is simple enough we can compute it manually as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.85\n",
    "P = nx.to_numpy_matrix(PR_graph)\n",
    "P = P/np.sum(P,axis=1)\n",
    "Google_matrix = alpha * P + (1-alpha)/P.shape[0] * np.ones(P.shape)\n",
    "Google_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 100\n",
    "v = np.ones(P.shape[0])/P.shape[0]\n",
    "for i in range(iterations):\n",
    "    v = v * Google_matrix\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this presentation we learned about Markov chains, starting with their mathematical definition, then we saw an example displayed as a graph.  \n",
    "We then saw an example of a graph for text generation, and discussed its relevancy to autocomplete.  \n",
    "Finally we looked at Google's classic PageRank algorithm in terms of Markov Chains for modeling a user surfing through a network.  \n",
    "Hopefully this presentation has given useful insights and intuitions behind the ubiquitous concept of Markov Chains."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
